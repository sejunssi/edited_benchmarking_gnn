{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization of Dataset Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    IMPORTING LIBS\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import socket\n",
    "import time\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "True\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import torch\n",
    "from data.data import LoadData # import dataset\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. TU Datasets Visualization Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def visualize_TUs_data(DATASET_NAME):\n",
    "    print(\"[I] Loading data (notebook) ...\")\n",
    "    dataset = LoadData(DATASET_NAME)\n",
    "    trainset, valset, testset = dataset.train, dataset.val, dataset.test\n",
    "    print(\"[I] Finished loading.\")\n",
    "\n",
    "    # Original Statistics\n",
    "    num_nodes, graph_labels = [], []\n",
    "    for split in [dataset.train, dataset.test, dataset.val]:\n",
    "        num_nodes += [g.number_of_nodes() for g in split[0][:][0]]\n",
    "        graph_labels += split[0][:][1]\n",
    "    orig_mean, orig_std, orig_max, orig_min = np.mean(num_nodes), np.std(num_nodes), np.max(num_nodes), np.min(num_nodes)\n",
    "\n",
    "    max_nodes = int(orig_mean+orig_std)\n",
    "    print(\"Original Dataset Statistics:\\n\")\n",
    "    print(\"Max nodes {}, Min nodes {}\\n\".format(orig_max, orig_min))\n",
    "    print(\"Mean no. of nodes {}, S.d. {}\\n\".format(orig_mean, orig_std))\n",
    "\n",
    "    num_nodes, graph_labels = [], []\n",
    "    for split in [dataset.train, dataset.test, dataset.val]:\n",
    "        split_num_nodes, split_graph_labels = [], []\n",
    "        g = split[0][:][0]\n",
    "        lab = split[0][:][1]\n",
    "        for idx in range(len(g)):\n",
    "            if g[idx].number_of_nodes() < max_nodes:\n",
    "                split_num_nodes.append(g[idx].number_of_nodes())\n",
    "                split_graph_labels.append(lab[idx])\n",
    "\n",
    "\n",
    "        num_nodes += split_num_nodes\n",
    "        graph_labels += split_graph_labels\n",
    "    label_bins = len(np.unique(graph_labels))\n",
    "    \n",
    "    print(\"VISUALIZATIONS:\\nMax nodes in consideration: {}\".format(max_nodes))\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(121)\n",
    "    \n",
    "    plt.hist(num_nodes, bins=len(np.unique(num_nodes)))\n",
    "    plt.xlabel('Number of Nodes in Graph', fontsize=12)\n",
    "    plt.ylabel('Count', fontsize=12)\n",
    "    \n",
    "    plt.subplot(122)\n",
    "    plt.hist2d(graph_labels, num_nodes, bins=[label_bins, 20])\n",
    "    plt.xlabel(r'Graph label', fontsize=12)\n",
    "    plt.ylabel(r'Graph size (number of nodes)', fontsize=12)\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Correlation between graph size (number of nodes) and labels: %.2f\" % np.corrcoef(graph_labels, num_nodes)[0,1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. TU Dataset ENZYMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "[I] Loading data (notebook) ...\n",
      "[!] Dataset:  ENZYMES\n",
      "[!] Splitting the data into train/val/test ...\n"
     ],
     "output_type": "stream"
    },
    {
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-b710eb72b7ad>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mvisualize_TUs_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ENZYMES'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-0ee9a86ceeee>\u001b[0m in \u001b[0;36mvisualize_TUs_data\u001b[1;34m(DATASET_NAME)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mvisualize_TUs_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDATASET_NAME\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"[I] Loading data (notebook) ...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLoadData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDATASET_NAME\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mtrainset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"[I] Finished loading.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\project\\benchmarking-gnns\\data\\data.py\u001b[0m in \u001b[0;36mLoadData\u001b[1;34m(DATASET_NAME)\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[0mTU_DATASETS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'COLLAB'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ENZYMES'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'DD'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'PROTEINS_full'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mDATASET_NAME\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mTU_DATASETS\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mTUsDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDATASET_NAME\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;31m# handling for SBM datasets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\project\\benchmarking-gnns\\data\\TUs.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m         \u001b[1;31m# this function splits data into train/val/test and returns the indices\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 151\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_all_split_idx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\project\\benchmarking-gnns\\data\\TUs.py\u001b[0m in \u001b[0;36mget_all_split_idx\u001b[1;34m(dataset)\u001b[0m\n\u001b[0;32m     54\u001b[0m             \u001b[0mremain_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m             \u001b[0mremain_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mformat_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mremain_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m             \u001b[1;31m# Gets final 'train' and 'val'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'format_dataset' is not defined"
     ],
     "ename": "NameError",
     "evalue": "name 'format_dataset' is not defined",
     "output_type": "error"
    }
   ],
   "source": [
    "visualize_TUs_data('ENZYMES')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. TU Datasets DD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "visualize_TUs_data('DD')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. TU Datasets PROTEINS_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "visualize_TUs_data('PROTEINS_full')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. MNIST/CIFAR10 Superpixels Dataset Visualization Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def visualize_superpixels_data(DATASET_NAME):\n",
    "    print(\"[I] Loading data (notebook) ...\")\n",
    "    dataset = LoadData(DATASET_NAME)\n",
    "    trainset, valset, testset = dataset.train, dataset.val, dataset.test\n",
    "    print(\"[I] Finished loading.\")\n",
    "\n",
    "    # Original Statistics\n",
    "    num_nodes, graph_labels = [], []\n",
    "    for split in [dataset.train, dataset.test, dataset.val]:\n",
    "        num_nodes += [g.number_of_nodes() for g in split[:][0]]\n",
    "        graph_labels += list(split[:][1].numpy())\n",
    "    orig_mean, orig_std, orig_max, orig_min = np.mean(num_nodes), np.std(num_nodes), np.max(num_nodes), np.min(num_nodes)\n",
    "\n",
    "    max_nodes = int(orig_mean+orig_std)\n",
    "    print(\"Original Dataset Statistics:\\n\")\n",
    "    print(\"Max nodes {}, Min nodes {}\\n\".format(orig_max, orig_min))\n",
    "    print(\"Mean no. of nodes {}, S.d. {}\\n\".format(orig_mean, orig_std))\n",
    "\n",
    "    num_nodes, graph_labels = [], []\n",
    "    for split in [dataset.train, dataset.test, dataset.val]:\n",
    "        split_num_nodes, split_graph_labels = [], []\n",
    "        g = split[:][0]\n",
    "        lab = split[:][1]\n",
    "        for idx in range(len(g)):\n",
    "            if g[idx].number_of_nodes() < max_nodes:\n",
    "                split_num_nodes.append(g[idx].number_of_nodes())\n",
    "                split_graph_labels.append(lab[idx].item())\n",
    "\n",
    "\n",
    "        num_nodes += split_num_nodes\n",
    "        graph_labels += split_graph_labels\n",
    "    label_bins = len(np.unique(graph_labels))\n",
    "    \n",
    "    print(\"VISUALIZATIONS:\\nMax nodes in consideration: {}\".format(max_nodes))\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(121)\n",
    "    \n",
    "    plt.hist(num_nodes, bins=len(np.unique(num_nodes)))\n",
    "    plt.xlabel('Number of Nodes in Graph', fontsize=12)\n",
    "    plt.ylabel('Count', fontsize=12)\n",
    "    \n",
    "    plt.subplot(122)\n",
    "    plt.hist2d(graph_labels, num_nodes, bins=[label_bins, 20])\n",
    "    plt.xlabel(r'Graph label', fontsize=12)\n",
    "    plt.ylabel(r'Graph size (number of nodes)', fontsize=12)\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "DATASET_NAME = 'MNIST'\n",
    "\n",
    "print(\"[I] Loading data (notebook) ...\")\n",
    "dataset = LoadData(DATASET_NAME)\n",
    "trainset, valset, testset = dataset.train, dataset.val, dataset.test\n",
    "print(\"[I] Finished loading.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Superpixels Dataset MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "visualize_superpixels_data('MNIST')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "visualize_superpixels_data('CIFAR10')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ZINC Molecules Dataset Visualization Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def visualize_molecules_data(DATASET_NAME):\n",
    "    print(\"[I] Loading data (notebook) ...\")\n",
    "    dataset = LoadData(DATASET_NAME)\n",
    "    trainset, valset, testset = dataset.train, dataset.val, dataset.test\n",
    "    print(\"[I] Finished loading.\")\n",
    "    \n",
    "    # Original Statistics\n",
    "    num_nodes, graph_scores = [], []\n",
    "    for split in [dataset.train, dataset.test, dataset.val]:\n",
    "        num_nodes += [g.number_of_nodes() for g in split[:][0]]\n",
    "        graph_scores += split[:][1]\n",
    "    orig_mean, orig_std, orig_max, orig_min = np.mean(num_nodes), np.std(num_nodes), np.max(num_nodes), np.min(num_nodes)\n",
    "\n",
    "    max_nodes = int(orig_mean+orig_std)\n",
    "    print(\"Original Dataset Statistics:\\n\")\n",
    "    print(\"Max nodes {}, Min nodes {}\\n\".format(orig_max, orig_min))\n",
    "    print(\"Mean no. of nodes {}, S.d. {}\\n\".format(orig_mean, orig_std))\n",
    "\n",
    "    num_nodes, graph_scores = [], []\n",
    "    for split in [dataset.train, dataset.test, dataset.val]:\n",
    "        split_num_nodes, split_graph_scores = [], []\n",
    "        g = split[:][0]\n",
    "        sco = split[:][1]\n",
    "        for idx in range(len(g)):\n",
    "            if g[idx].number_of_nodes() < max_nodes:\n",
    "                split_num_nodes.append(g[idx].number_of_nodes())\n",
    "                split_graph_scores.append(sco[idx].item())\n",
    "\n",
    "\n",
    "        num_nodes += split_num_nodes\n",
    "        graph_scores += split_graph_scores\n",
    "\n",
    "    print(\"VISUALIZATIONS:\\nMax nodes in consideration: {}\".format(max_nodes))\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(121)\n",
    "\n",
    "    plt.hist(num_nodes, bins=len(np.unique(num_nodes)))\n",
    "    plt.xlabel('Number of Nodes in Graph', fontsize=12)\n",
    "    plt.ylabel('Count', fontsize=12)\n",
    "    plt.show()\n",
    "\n",
    "    print(\"Mean of graph regression scores and s.d. [{:.4f}] (+/-) [{:.4f}]\".format(np.mean(graph_scores), np.std(graph_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "visualize_molecules_data('ZINC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. VOC Superpixels Dataset Visualization Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def visualize_superpixels_node_data(DATASET_NAME):\n",
    "    print(\"[I] Loading data (notebook) ...\")\n",
    "    dataset = LoadData(DATASET_NAME)\n",
    "    trainset, valset, testset = dataset.train, dataset.val, dataset.test\n",
    "    print(\"[I] Finished loading.\")\n",
    "    \n",
    "        # Original Statistics\n",
    "    num_nodes, graph_labels = [], []\n",
    "    for split in [dataset.train, dataset.test, dataset.val]:\n",
    "        num_nodes += [g.number_of_nodes() for g in split[:][0]]\n",
    "        graph_labels += split[:][1]\n",
    "    orig_mean, orig_std, orig_max, orig_min = np.mean(num_nodes), np.std(num_nodes), np.max(num_nodes), np.min(num_nodes)\n",
    "\n",
    "    max_nodes = int(orig_mean+orig_std)\n",
    "    print(\"Original Dataset Statistics:\\n\")\n",
    "    print(\"Max nodes {}, Min nodes {}\\n\".format(orig_max, orig_min))\n",
    "    print(\"Mean no. of nodes {}, S.d. {}\\n\".format(orig_mean, orig_std))\n",
    "\n",
    "    num_nodes, graph_node_labels = [], []\n",
    "    for split in [dataset.train, dataset.test, dataset.val]:\n",
    "        split_num_nodes, split_graph_labels = [], []\n",
    "        g = split[:][0]\n",
    "        lab = split[:][1]\n",
    "        for idx in range(len(g)):\n",
    "            if g[idx].number_of_nodes() < max_nodes:\n",
    "                split_num_nodes.append(g[idx].number_of_nodes())\n",
    "                split_graph_labels.append(len(np.unique(lab[idx])))\n",
    "\n",
    "\n",
    "        num_nodes += split_num_nodes\n",
    "        graph_node_labels += split_graph_labels\n",
    "    # label_bins = len(np.unique(graph_labels))\n",
    "\n",
    "    print(\"VISUALIZATIONS:\\nMax nodes in consideration: {}\".format(max_nodes))\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(121)\n",
    "\n",
    "    plt.hist(num_nodes, bins=len(np.unique(num_nodes)))\n",
    "    plt.xlabel('Number of Nodes in Graph', fontsize=12)\n",
    "    plt.ylabel('Count', fontsize=12)\n",
    "\n",
    "    plt.subplot(122)\n",
    "    plt.hist(graph_node_labels, bins=len(np.unique(graph_node_labels)))\n",
    "    plt.xlabel('Number Unique Node Labels in Graph', fontsize=12)\n",
    "    plt.ylabel('Count', fontsize=12)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "visualize_superpixels_node_data('VOC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}